{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48d57100-b972-4741-be5f-f2f800632e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.2.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import plotly.express as px\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "import praw\n",
    "from data import *\n",
    "import time\n",
    "import squarify\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re   # removes links\n",
    "import en_core_web_sm\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adc5b57e-e9c4-490f-b04d-bee1a577ae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#symbols = pd.read_csv('comment_folder/sp500.csv')\n",
    "#symbols = sp500.values.tolist()\n",
    "#symbols['Symbol'] = symbols['Symbol'].str[0:4]\n",
    "#symbols = sp500.values.tolist()\n",
    "symbols = [\"MMM \",\"AOS \",\"ABT \",\"ABBV \",\"ABMD \",\"ACN \",\"ATVI \",\"ADM \",\"ADBE \",\"AAP \",\"AMD \",\"AES \",\"AFL \",\"APD \",\"AKAM \",\"ALK \",\"ALB \",\"ARE \",\"ALGN \",\"ALLE \",\"LNT \",\"GOOGL \",\"GOOG \",\n",
    "           \"AMZN \",\"AMC \",\"AEE \",\"AAL \",\"AEP \",\"AXP \",\"AIG \",\"AMT \",\"AWK \",\"AMP \",\"ABC \",\"AME \",\"AMGN \",\"APH \",\"ADI \",\"ANSS \",\"ANTM \",\"AON \",\"APA \",\"AAPL \",\"AMAT \",\"APTV \",\"ANET \",\"AJG \",\n",
    "           \"AIZ \",\"ATO \",\"ADSK \",\"ADP \",\"AZO \",\"AVB \",\"AVY \",\"BKR \",\"BLL \",\"BAC \",\"BBWI \",\"BAX \",\"BDX \",\"BRK.B \",\"BBY \",\"BIO \",\"BIIB \",\"BLK \",\"BK \",\"BKNG \",\"BWA \",\"BXP \",\"BSX \",\"BMY \",\n",
    "           \"AVGO \",\"BF.B \",\"CHRW \",\"COG \",\"CDNS \",\"CZR \",\"CPB \",\"COF \",\"CAH \",\"KMX \",\"CCL \",\"CARR \",\"CTLT \",\"CAT \",\"CBOE \",\"CBRE \",\"CDW \",\"CNC \",\"CNP \",\"CERN \",\"CRL \",\"SCHW \",\n",
    "           \"CHTR \",\"CVX \",\"CMG \",\"CHD \",\"CINF \",\"CTAS \",\"CSCO \",\"CFG \",\"CTXS \",\"CLX \",\"CME \",\"CMS \",\"KO \",\"CTSH \",\"CMCSA \",\"CMA \",\"CAG \",\"COP \",\"STZ \",\"CPRT \",\"GLW \",\n",
    "           \"CTVA \",\"COST \",\"CCI \",\"CSX \",\"CMI \",\"CVS \",\"DHI \",\"DHR \",\"DRI \",\"DVA \",\"DAL \",\"XRAY \",\"DVN \",\"DXCM \",\"FANG \",\"DLR \",\"DFS \",\"DISCA \",\"DISCK \",\"DISH \",\"DLTR \",\"DPZ \",\n",
    "           \"DOV \",\"DOW \",\"DTE \",\"DUK \",\"DRE \",\"DXC \",\"EMN \",\"ETN \",\"EBAY \",\"ECL \",\"EIX \",\"EW \",\"LLY \",\"EMR \",\"ENPH \",\"ETR \",\"EOG \",\"EFX \",\"EQIX \",\"EQR \",\"ESS \",\"ETSY \",\"EVRG \",\n",
    "           \"EXC \",\"EXPE \",\"EXPD \",\"EXR \",\"XOM \",\"FFIV \",\"FB \",\"FAST \",\"FRT \",\"FDX \",\"FIS \",\"FITB \",\"FRC \",\"FISV \",\"FLT \",\"FMC \",\"FTNT \",\"FTV \",\"FBHS \",\"FOXA \",\"FOX \",\"BEN \",\"FCX \",\n",
    "           \"GPS \",\"GRMN \",\"GNRC \",\"GD \",\"GIS \",\"GM \",\"GPC \",\"GILD \",\"GPN \",\"HAL \",\"HBI \",\"HAS \",\"HCA \",\"PEAK \",\"HSIC \",\"HES \",\"HPE \",\"HLT \",\"HOLX \",\"HD \",\"HON \",\"HRL \",\"HST \",\n",
    "           \"HWM \",\"HPQ \",\"HUM \",\"HBAN \",\"HII \",\"IBM \",\"IEX \",\"IDXX \",\"INFO \",\"ITW \",\"ILMN \",\"INCY \",\"IR \",\"INTC \",\"ICE \",\"IFF \",\"IPG \",\"INTU \",\"ISRG \",\"IVZ \",\"IPGP \",\"IQV \",\"IRM \",\"JBHT \",\n",
    "           \"JKHY \",\"SJM \",\"JNJ \",\"JCI \",\"JPM \",\"JNPR \",\"KSU \",\"KEY \",\"KEYS \",\"KMB \",\"KIM \",\"KMI \",\"KLAC \",\"KHC \",\"KR \",\"LHX \",\"LH \",\"LRCX \",\"LW \",\"LVS \",\"LEG \",\"LDOS \",\"LEN \",\"LNC \",\"LIN \",\n",
    "           \"LYV \",\"LKQ \",\"LMT \",\"LOW \",\"LUMN \",\"LYB \",\"MTB \",\"MRO \",\"MPC \",\"MKTX \",\"MAR \",\"MMC \",\"MLM \",\"MAS \",\"MA \",\"MXIM \",\"MKC \",\"MCD \",\"MCK \",\"MDT \",\"MRK \",\"MET \",\"MTD \",\"MGM \",\"MCHP \",\n",
    "           \"MU \",\"MSFT \",\"MAA \",\"MRNA \",\"MHK \",\"TAP \",\"MDLZ \",\"MPWR \",\"MNST \",\"MCO \",\"MS \",\"MSI \",\"MSCI \",\"NDAQ \",\"NTAP \",\"NFLX \",\"NWL \",\"NEM \",\"NWSA \",\"NWS \",\"NEE \",\"NLSN \",\"NK \",\"NSC \",\n",
    "           \"NTRS \",\"NOC \",\"NLOK \",\"NCLH \",\"NOV \",\"NRG \",\"NUE \",\"NVDA \",\"NVR \",\"NXPI \",\"ORLY \",\"OXY \",\"ODFL \",\"OMC \",\"OKE \",\"ORCL \",\"OGN \",\"OTIS \",\"PCAR \",\"PKG \",\"PH \",\"PAYX \",\"PAYC \",\"PYPL \",\n",
    "           \"PENN \",\"PNR \",\"PBCT \",\"PEP \",\"PKI \",\"PRGO \",\"PFE \",\"GE \",\"PSX \",\"PNW \",\"PXD \",\"PNC \",\"POOL \",\"PPG \",\"PPL \",\"PFG \",\"PG \",\"PGR \",\"PLD \",\"PRU \",\"PTC \",\"PEG \",\"PSA \",\"PHM \",\"PVH \",\"QRVO \",\n",
    "           \"QCOM \",\"PWR \",\"DGX \",\"RL \",\"RJF \",\"RTX \",\"REG \",\"REGN \",\"RF \",\"RSG \",\"RMD \",\"RHI \",\"ROK \",\"ROL \",\"ROP \",\"ROST \",\"RCL \",\"SPGI \",\"CRM \",\"SBAC \",\"SLB \",\"STX \",\"SEE \",\"SRE \",\"NOW \",\n",
    "           \"SHW \",\"SPG \",\"SWKS \",\"SNA \",\"LUV \",\"SWK \",\"SBUX \",\"STT \",\"STE \",\"SYK \",\"SIVB \",\"SYF \",\"SNPS \",\"SYY \",\"TMUS \",\"TROW \",\"TTWO \",\"TPR \",\"TGT \",\"TEL \",\"TDY \",\"TFX \",\"TER \",\"TSLA \",\n",
    "           \"TXN \",\"TXT \",\"COO \",\"HIG \",\"HSY \",\"MOS \",\"TRV \",\"DIS \",\"TMO \",\"TJX \",\"TSCO \",\"TT \",\"TDG \",\"TRMB \",\"TFC \",\"TWTR \",\"TYL \",\"TSN \",\"USB \",\"UDR \",\"ULTA \",\"UAA \",\"UA \",\"UNP \",\"UAL \",\"UPS \",\n",
    "           \"URI \",\"UNH \",\"UHS \",\"UNM \",\"VLO \",\"VTR \",\"VRSN \",\"VRSK \",\"VZ \",\"VRTX \",\"VFC \",\"VIAC \",\"VTRS \",\"VNO \",\"VMC \",\"WRB \",\"GWW \",\"WAB \",\"WBA \",\"WMT \",\"WM \",\"WAT \",\"WEC \",\"WFC \",\"WELL \",\n",
    "           \"WST \",\"WDC \",\"WU \",\"WRK \",\"WY \",\"WHR \",\"WMB \",\"WLTW \",\"WYNN \",\"XEL \",\"XLNX \",\"XYL \",\"YUM \",\"ZBRA \",\"ZBH \",\"ZION \",\"ZTS \", \"GME \", 'BB ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb4f0c76-700f-459d-b1cd-40b9f1b6c1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Author</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Score</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>249</td>\n",
       "      <td>KarlMarx693</td>\n",
       "      <td>Is Jpow the most memed financial official ever?</td>\n",
       "      <td>13</td>\n",
       "      <td>6/16/2021 5:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>193</td>\n",
       "      <td>pr3dato8</td>\n",
       "      <td>Is it too late to get into $JPOW?</td>\n",
       "      <td>14</td>\n",
       "      <td>6/16/2021 5:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>404</td>\n",
       "      <td>dragonrider85</td>\n",
       "      <td>Gentlemen, it is with great pleasure to inform...</td>\n",
       "      <td>36</td>\n",
       "      <td>6/16/2021 5:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>403</td>\n",
       "      <td>MLKKO</td>\n",
       "      <td>Whos still holding BB?</td>\n",
       "      <td>152</td>\n",
       "      <td>6/16/2021 5:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127</td>\n",
       "      <td>None</td>\n",
       "      <td>Last week I went to go outside for a smoke and...</td>\n",
       "      <td>98</td>\n",
       "      <td>6/16/2021 5:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         Author  \\\n",
       "0         249    KarlMarx693   \n",
       "1         193       pr3dato8   \n",
       "2         404  dragonrider85   \n",
       "3         403          MLKKO   \n",
       "4         127           None   \n",
       "\n",
       "                                             Comment  Score       timestamp  \n",
       "0    Is Jpow the most memed financial official ever?     13  6/16/2021 5:06  \n",
       "1                  Is it too late to get into $JPOW?     14  6/16/2021 5:07  \n",
       "2  Gentlemen, it is with great pleasure to inform...     36  6/16/2021 5:09  \n",
       "3                             Whos still holding BB?    152  6/16/2021 5:11  \n",
       "4  Last week I went to go outside for a smoke and...     98  6/16/2021 5:15  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('comment_folder/all_comments.csv')\n",
    "#df = pd.read_csv('comment_folder/all_comments.csv')\n",
    "# df = df([\"Score\"] > 10)\n",
    "#df = df[df['Score'] > 10]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5668f485-acd0-4c01-946a-4d48e20670a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Author</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Score</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>symbols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28301</th>\n",
       "      <td>216</td>\n",
       "      <td>Hans-Diamond</td>\n",
       "      <td>\"Please explain your path to Fed Chair\"\\n\\n  \\...</td>\n",
       "      <td>10</td>\n",
       "      <td>8/17/2021 13:07</td>\n",
       "      <td>ARE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28354</th>\n",
       "      <td>314</td>\n",
       "      <td>Pifoot_trading</td>\n",
       "      <td>AAPL has declared war on all guys with small d...</td>\n",
       "      <td>8</td>\n",
       "      <td>8/17/2021 13:46</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28355</th>\n",
       "      <td>314</td>\n",
       "      <td>Pifoot_trading</td>\n",
       "      <td>AAPL has declared war on all guys with small d...</td>\n",
       "      <td>10</td>\n",
       "      <td>8/17/2021 13:46</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28402</th>\n",
       "      <td>101</td>\n",
       "      <td>prisonsexx</td>\n",
       "      <td>PFE calls saving my portfolio</td>\n",
       "      <td>13</td>\n",
       "      <td>8/17/2021 14:17</td>\n",
       "      <td>PFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28404</th>\n",
       "      <td>101</td>\n",
       "      <td>prisonsexx</td>\n",
       "      <td>PFE calls saving my portfolio</td>\n",
       "      <td>13</td>\n",
       "      <td>8/17/2021 14:17</td>\n",
       "      <td>PFE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0          Author  \\\n",
       "28301         216    Hans-Diamond   \n",
       "28354         314  Pifoot_trading   \n",
       "28355         314  Pifoot_trading   \n",
       "28402         101      prisonsexx   \n",
       "28404         101      prisonsexx   \n",
       "\n",
       "                                                 Comment  Score  \\\n",
       "28301  \"Please explain your path to Fed Chair\"\\n\\n  \\...     10   \n",
       "28354  AAPL has declared war on all guys with small d...      8   \n",
       "28355  AAPL has declared war on all guys with small d...     10   \n",
       "28402                      PFE calls saving my portfolio     13   \n",
       "28404                      PFE calls saving my portfolio     13   \n",
       "\n",
       "             timestamp symbols  \n",
       "28301  8/17/2021 13:07    ARE   \n",
       "28354  8/17/2021 13:46   AAPL   \n",
       "28355  8/17/2021 13:46   AAPL   \n",
       "28402  8/17/2021 14:17    PFE   \n",
       "28404  8/17/2021 14:17    PFE   "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_list = symbols\n",
    "\n",
    "df['symbols'] = df.Comment.str.extract('({0})'.format('|'.join(search_list)))\n",
    "symbols_df = df[~pd.isna(df.symbols)]\n",
    "\n",
    "symbols_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "525c4cd0-c840-486c-85d7-6329a0bd9599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#symbols_df = symbols_df[(symbols_df['timestamp'] > '2021-08-16 00:30:00') & (symbols_df['timestamp'] < '2021-08-17 23:00:00')]\n",
    "#symbols_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c2591f2-9edf-4237-9c6a-9179332bd6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TSLA     310\n",
       "BB       207\n",
       "AAPL     175\n",
       "MRNA     115\n",
       "NVDA      96\n",
       "AMD       94\n",
       "DTE       76\n",
       "MU        75\n",
       "ARE       55\n",
       "AMZN      55\n",
       "PFE       52\n",
       "AMC       48\n",
       "MSFT      41\n",
       "GME       38\n",
       "DIS       34\n",
       "Name: symbols, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_tickers = symbols_df['symbols'].value_counts().head(15)\n",
    "top_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80dd5b7e-dafd-4393-a5cc-c4c351311ed4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'set' object has no attribute 'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-64096a8f1a97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create stopword list:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstopwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtextt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomment\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcomment\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msymbols_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mComment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtextt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwordcloud\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bilinear'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'set' object has no attribute 'words'"
     ]
    }
   ],
   "source": [
    "# Create stopword list:\n",
    "stopwords = set(stopwords.words('english'))\n",
    "textt = \" \".join(comment for comment in symbols_df.Comment)\n",
    "wordcloud = WordCloud(stopwords=stopwords).generate(textt)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig('wordcloud11.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6032bd04-d6c7-440d-9e96-79fcf3f6c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign reviews with score > 3 as positive sentiment\n",
    "# score < 3 negative sentiment\n",
    "# remove score = 3\n",
    "#symbols_df = symbols_df[symbols_df['sentiment'] != 0]\n",
    "#symbols_df['sentiment'] = symbols_df['Score'].apply(lambda rating : +1 if rating > 0 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d91e100-12e8-4d2e-a22c-e43d2a3ed91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment calculation based on compound score\n",
    "def get_sentiment(score):\n",
    "    \"\"\"\n",
    "    Calculates the sentiment based on the compound score.\n",
    "    \"\"\"\n",
    "    result = 0  # Neutral by default\n",
    "    if score >= 0.01:  # Positive\n",
    "        result = 1\n",
    "    elif score <= -0.01:  # Negative\n",
    "        result = -1\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4c73453-b9cd-4002-9d0d-16a1d0319153",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb05d090-656e-45db-bfb2-c4d10384963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment scores dictionaries\n",
    "text_sent = {\n",
    "    \"text_compound\": [],\n",
    "    \"text_pos\": [],\n",
    "    \"text_neu\": [],\n",
    "    \"text_neg\": [],\n",
    "    \"sentiment\": [],\n",
    "}\n",
    "\n",
    "# Get sentiment for the text and the title\n",
    "for index, row in symbols_df.iterrows():\n",
    "    try:\n",
    "        # Sentiment scoring with VADER\n",
    "        \n",
    "        text_sentiment = analyzer.polarity_scores(row[\"Comment\"])\n",
    "        text_sent[\"text_compound\"].append(text_sentiment[\"compound\"])\n",
    "        text_sent[\"text_pos\"].append(text_sentiment[\"pos\"])\n",
    "        text_sent[\"text_neu\"].append(text_sentiment[\"neu\"])\n",
    "        text_sent[\"text_neg\"].append(text_sentiment[\"neg\"])\n",
    "        text_sent[\"sentiment\"].append(get_sentiment(text_sentiment[\"compound\"]))\n",
    "    \n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "# Attaching sentiment columns to the News DataFrame\n",
    "text_sentiment_df = pd.DataFrame(text_sent)\n",
    "symbols_df = symbols_df.join(text_sentiment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4f6168b-3a68-498c-bce3-e172eb097c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Author</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Score</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>symbols</th>\n",
       "      <th>text_compound</th>\n",
       "      <th>text_pos</th>\n",
       "      <th>text_neu</th>\n",
       "      <th>text_neg</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>RADIO02118</td>\n",
       "      <td>Remember when TSLA would go up 10% a week, eve...</td>\n",
       "      <td>51</td>\n",
       "      <td>6/16/2021 6:06</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>246</td>\n",
       "      <td>ktrash</td>\n",
       "      <td>Yellen going to steal the mic at FOMC today an...</td>\n",
       "      <td>43</td>\n",
       "      <td>6/16/2021 6:30</td>\n",
       "      <td>OMC</td>\n",
       "      <td>0.6940</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>254</td>\n",
       "      <td>ImHereForLaughs58</td>\n",
       "      <td>BB may be a long plan now</td>\n",
       "      <td>14</td>\n",
       "      <td>6/16/2021 7:30</td>\n",
       "      <td>BB</td>\n",
       "      <td>0.7430</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>321</td>\n",
       "      <td>Arizonaj9</td>\n",
       "      <td>WISH CLF KMI go</td>\n",
       "      <td>13</td>\n",
       "      <td>6/16/2021 8:12</td>\n",
       "      <td>KMI</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>413</td>\n",
       "      <td>JayArlington</td>\n",
       "      <td>2 Steel companies (NUE and STLD) just revised ...</td>\n",
       "      <td>11</td>\n",
       "      <td>6/16/2021 8:14</td>\n",
       "      <td>NUE</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0             Author  \\\n",
       "16          10         RADIO02118   \n",
       "23         246             ktrash   \n",
       "47         254  ImHereForLaughs58   \n",
       "66         321          Arizonaj9   \n",
       "69         413       JayArlington   \n",
       "\n",
       "                                              Comment  Score       timestamp  \\\n",
       "16  Remember when TSLA would go up 10% a week, eve...     51  6/16/2021 6:06   \n",
       "23  Yellen going to steal the mic at FOMC today an...     43  6/16/2021 6:30   \n",
       "47                          BB may be a long plan now     14  6/16/2021 7:30   \n",
       "66                                    WISH CLF KMI go     13  6/16/2021 8:12   \n",
       "69  2 Steel companies (NUE and STLD) just revised ...     11  6/16/2021 8:14   \n",
       "\n",
       "   symbols  text_compound  text_pos  text_neu  text_neg  sentiment  \n",
       "16   TSLA          0.0000     0.000     1.000       0.0        0.0  \n",
       "23    OMC          0.6940     0.656     0.344       0.0        1.0  \n",
       "47     BB          0.7430     0.310     0.690       0.0        1.0  \n",
       "66    KMI          0.0000     0.000     1.000       0.0        0.0  \n",
       "69    NUE          0.6908     0.655     0.345       0.0        1.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2722e9e9-ea74-438e-9d85-9a958608a5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>symbols</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Remember when TSLA would go up 10% a week, eve...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Yellen going to steal the mic at FOMC today an...</td>\n",
       "      <td>OMC</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>BB may be a long plan now</td>\n",
       "      <td>BB</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>WISH CLF KMI go</td>\n",
       "      <td>KMI</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2 Steel companies (NUE and STLD) just revised ...</td>\n",
       "      <td>NUE</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>I need power hour to send NVDA to $780</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>Got fucked by 0tde NVDA calls...I guess no mor...</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>Got fucked by 0tde NVDA calls...I guess no mor...</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>I need to load up on more TSLA calls. $45k isn...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>I need to load up on more TSLA calls. $45k isn...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment symbols  sentiment\n",
       "16    Remember when TSLA would go up 10% a week, eve...   TSLA         0.0\n",
       "23    Yellen going to steal the mic at FOMC today an...    OMC         1.0\n",
       "47                            BB may be a long plan now     BB         1.0\n",
       "66                                      WISH CLF KMI go    KMI         0.0\n",
       "69    2 Steel companies (NUE and STLD) just revised ...    NUE         1.0\n",
       "...                                                 ...     ...        ...\n",
       "1667             I need power hour to send NVDA to $780   NVDA         1.0\n",
       "1684  Got fucked by 0tde NVDA calls...I guess no mor...   NVDA         0.0\n",
       "1685  Got fucked by 0tde NVDA calls...I guess no mor...   NVDA         0.0\n",
       "1724  I need to load up on more TSLA calls. $45k isn...   TSLA         0.0\n",
       "1725  I need to load up on more TSLA calls. $45k isn...   TSLA         0.0\n",
       "\n",
       "[104 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNew = symbols_df[['Comment',\"symbols\",'sentiment']]\n",
    "dfNew = dfNew.dropna()\n",
    "dfNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93e7575d-a54d-412f-852b-8a45289e788a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbols</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMD</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>OMC</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GME</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMC</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>VIAC</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SEE</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NUE</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>XOM</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>IR</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DTE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>OKE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BB</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TTWO</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KMI</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HES</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LLY</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HAS</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARE</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TER</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   symbols  sentiment\n",
       "14   NVDA        10.0\n",
       "0    AAPL         2.0\n",
       "2     AMD         2.0\n",
       "16    OMC         2.0\n",
       "7     GME         2.0\n",
       "1     AMC         1.0\n",
       "21   VIAC         1.0\n",
       "17    SEE         1.0\n",
       "13    NUE         1.0\n",
       "22    XOM         1.0\n",
       "10     IR         0.0\n",
       "6     DTE         0.0\n",
       "15    OKE         0.0\n",
       "5      BB         0.0\n",
       "20   TTWO         0.0\n",
       "3    AMZN         0.0\n",
       "11    KMI         0.0\n",
       "9     HES        -1.0\n",
       "12    LLY        -1.0\n",
       "8     HAS        -1.0\n",
       "4     ARE        -1.0\n",
       "18    TER        -2.0\n",
       "19   TSLA        -5.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff = dfNew.groupby([\"symbols\"]).sentiment.sum().reset_index()\n",
    "dff = dff.sort_values(by='sentiment', ascending=False)\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "365e50c7-2668-45a6-9e26-aa6032241112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random split train and test data\n",
    "index = dfNew.index\n",
    "dfNew['random_number'] = np.random.randn(len(index))\n",
    "train = dfNew[dfNew['random_number'] <= 0.8]\n",
    "test = dfNew[dfNew['random_number'] > 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f189e4f-34f3-42e3-8736-9b762bff7aff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-b5c58da57621>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_pattern\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr'\\b\\w+\\b'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Comment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtest_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Comment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1200\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[0;32m   1203\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1131\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n\u001b[0m\u001b[0;32m   1134\u001b[0m                                  \" contain stop words\")\n\u001b[0;32m   1135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "train_matrix = vectorizer.fit_transform(train['Comment'])\n",
    "test_matrix = vectorizer.transform(test['Comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2733cd1-382a-459c-a14a-857100f210e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52366e53-58ba-430b-b8e3-b18c66981592",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_matrix\n",
    "X_test = test_matrix\n",
    "y_train = train['sentiment']\n",
    "y_test = test['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d05a67-a2ac-4cd3-8ef7-1a6d74aa63c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb20a08-1648-4ac6-a256-395bb10175c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0134dfe5-29ef-429c-9a03-87df46e2998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find accuracy, precision, recall:\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "new = np.asarray(y_test)\n",
    "confusion_matrix(predictions,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bcdf50-5fcb-484a-b213-128c930efaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7cab1e-df5d-4eeb-84a3-f17cf6387ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
